{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2865a13d",
   "metadata": {},
   "source": [
    "* Describe what a deep neural network is.\n",
    "* Implement deep neural networks in Pytorch.\n",
    "* Build a deep Neural network in PyTorch using nn.Module list.\n",
    "* Define dropout.\n",
    "* Implement the dropout method in PyTorch.\n",
    "* Create a layer.\n",
    "* Discuss the initialization of the weights in a Neural Network.\n",
    "* Discuss the problem of not initializing the Weights in a Neural Network model correctly and how to fix it.\n",
    "* List different initializing methods in Pytorch.\n",
    "* Explain what gradient descent with momentum is, and its applications in optimizing paramaters.\n",
    "* Describe what batch normalization is and use it in Pytorch.\n",
    "* Discuss why batch normalization works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfebe8b",
   "metadata": {},
   "source": [
    "## What is Deep Neural Networks?\n",
    "Adding more neurons in the layer will make a complex decision function to classify non-linearly separable data, but this also increase the chances of overfitting.  By adding more hidden layers, we usally increase the performance of our model, while decreasing the risk of overfitting.\n",
    "\n",
    "also, if a network has more than one hidden layer, then it is called deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f322a8",
   "metadata": {},
   "source": [
    "## Deep Neural Network of 2 Hidden Layer and testing sigmoid, tanh and relu Activation functions with MNIST Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c52dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "#manually seeding\n",
    "torch.manual_seed(2)\n",
    "\n",
    "#create the model class using sigmoid as the activation function\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1= nn.Linear(D_in, H1)\n",
    "        self.linear2= nn.Linear(H1, H2)\n",
    "        self.linear3= nn.Linear(H2, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x= torch.sigmoid(self.linear1(x))\n",
    "        x= torch.sigmoid(self.linear2(x))\n",
    "        x= self.linear3(x)\n",
    "        return x\n",
    "\n",
    "#create the model class using tanh as the activation function\n",
    "class NetTanh(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(NetTanh,self).__init__()\n",
    "        self.linear1= nn.Linear(D_in, H1)\n",
    "        self.linear2= nn.Linear(H1, H2)\n",
    "        self.linear3= nn.Linear(H2, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x= torch.tanh(self.linear1(x))\n",
    "        x= torch.tanh(self.linear2(x))\n",
    "        x= self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the model class using Relu as a activation function\n",
    "class NetRelu(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(NetRelu, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))  \n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "# function to train the model\n",
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [], 'validation_accuracy': []}  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "        \n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            _, label = torch.max(z, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "    \n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    \n",
    "    return useful_stuff\n",
    "\n",
    "\n",
    "#load the training and validation dataset\n",
    "train_dataset = dsets.MNIST(root='./resources/data', train=True, download=True, transform=transforms.ToTensor())\n",
    "validation_dataset = dsets.MNIST(root='./resources/data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# Create the criterion function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Create the training data loader and validation data loader object\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)\n",
    "\n",
    "\n",
    "# Set the parameters for create the model\n",
    "input_dim = 28 * 28\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 50\n",
    "output_dim = 10\n",
    "\n",
    "\n",
    "# Set the number of iterations\n",
    "cust_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95e7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with sigmoid function\n",
    "learning_rate = 0.01\n",
    "model = Net(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a2d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with tanh function\n",
    "learning_rate = 0.01\n",
    "model_Tanh = NetTanh(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "optimizer = torch.optim.SGD(model_Tanh.parameters(), lr=learning_rate)\n",
    "training_results_tanch = train(model_Tanh, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df583e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with relu function\n",
    "learning_rate = 0.01\n",
    "modelRelu = NetRelu(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "optimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\n",
    "training_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f254736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the training loss\n",
    "plt.plot(training_results_tanch['training_loss'][::50], label='tanh')\n",
    "plt.plot(training_results['training_loss'][::50], label='sigmoid')\n",
    "plt.plot(training_results_relu['training_loss'][::50], label='relu')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training loss iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the validation loss\n",
    "plt.plot(training_results_tanch['validation_accuracy'], label = 'tanh')\n",
    "plt.plot(training_results['validation_accuracy'], label = 'sigmoid')\n",
    "plt.plot(training_results_relu['validation_accuracy'], label = 'relu') \n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('Iteration')   \n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
