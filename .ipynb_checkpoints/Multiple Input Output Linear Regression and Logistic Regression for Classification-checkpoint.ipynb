{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c24442",
   "metadata": {},
   "source": [
    "## Multiple Input Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial parameters: [Parameter containing:\n",
      "tensor([[ 0.3784, -0.3760]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6900], requires_grad=True)]\n",
      "Calculated loss during each epoch:  [12.293909899890423, 1.9301671225111932, 0.20295447146054357, 0.10102170838217717, 0.09617247931601014, 0.0957897537809913, 0.09574325670109829, 0.09573701389308553, 0.09573616323905298, 0.09573607365018688, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508, 0.095736066592508]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "#set the random seed to 1\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(LR,self).__init__()\n",
    "        self.linear= nn.Linear(input_size, output_size)\n",
    "    def forward(self,x):\n",
    "        out= self.linear(x)\n",
    "        return out\n",
    "\n",
    "#to create synthetic data\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "class Data2D(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x= torch.zeros(20,2)\n",
    "        self.x[:,0]= torch.arange(-1,1,0.1)\n",
    "        self.x[:,1]= torch.arange(-1,1,0.1)\n",
    "        self.w= torch.tensor([[1.0],[1.0]])\n",
    "        self.b= 1\n",
    "        self.f= torch.mm(self.x, self.w)+self.b\n",
    "        #torch.rand() generates numbers of mean 0 and standard deviation 1.\n",
    "        # multiplying by 0.1 means, we are reducing the magnitude by 10 times, Inshort we are reducing the spread.\n",
    "        self.y= self.f + 0.1*torch.randn((self.x.shape[0],1))\n",
    "        self.len = self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "data_set= Data2D()\n",
    "criterion= nn.MSELoss()\n",
    "trainloader= DataLoader(dataset=data_set, batch_size=2)\n",
    "\n",
    "\n",
    "model= LR(input_size=2, output_size=1)\n",
    "print(\"The initial parameters:\", list(model.parameters()))\n",
    "optimizer= optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#training\n",
    "LOSS= []\n",
    "epochs= 100\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total=0\n",
    "        for x,y in trainloader:\n",
    "            yhat= model(x)\n",
    "            loss= criterion(yhat,y)\n",
    "            optimizer.zero_grad()\n",
    "            #calculates derivative of loss wrt each learnable parameter\n",
    "            loss.backward()\n",
    "            #update the parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "            total+= loss.item()\n",
    "        LOSS.append(total)\n",
    "        \n",
    "        \n",
    "train_model(epochs)\n",
    "\n",
    "\n",
    "print(\"Calculated loss during each epoch: \",LOSS)\n",
    "#show error reduced after each epoch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a plot\n",
    "plt.plot(LOSS[:20], marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epoch')\n",
    "plt.title('loss v/s epoch graph')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac9b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
