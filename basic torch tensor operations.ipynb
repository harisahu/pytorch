{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1451534",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d2977",
   "metadata": {},
   "source": [
    "Here are the basic types of tensors along with their dimensions and some of their common operations:\n",
    "\n",
    "1. Scalar (0D Tensor):\n",
    "    A scalar tensor is a single value with no dimensions.\n",
    "    Example: 5, -3.14\n",
    "    Operations: Scalars are used as the base elements for mathematical operations.\n",
    "\n",
    "2. 1D Tensor (Vector):\n",
    "    A 1D tensor, often referred to as a vector, has one dimension.\n",
    "    Example: [1, 2, 3, 4, 5]\n",
    "    Operations: You can perform vector addition, subtraction, element-wise multiplication, and more.\n",
    "\n",
    "3. 2D Tensor (Matrix):\n",
    "    A 2D tensor, or matrix, has two dimensions: rows and columns.\n",
    "    Example:\n",
    "    [\n",
    "      [1, 2, 3],\n",
    "      [4, 5, 6],\n",
    "      [7, 8, 9]\n",
    "    ]\n",
    "    Operations: Matrix multiplication, element-wise operations, transposition, and more.\n",
    "\n",
    "3. 3D Tensor:\n",
    "    A 3D tensor has three dimensions: depth, rows, and columns.\n",
    "    Example:\n",
    "    [\n",
    "      [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6]\n",
    "      ],\n",
    "      [\n",
    "        [7, 8, 9],\n",
    "        [10, 11, 12]\n",
    "      ]\n",
    "    ]\n",
    "    Operations: Used for operations involving 3D data, such as RGB images or time series data.\n",
    "\n",
    "Common operations on tensors include:\n",
    "1. Element-wise Operations: Operations performed independently on each element of a tensor.\n",
    "2. Matrix Multiplication: Computing the dot product of two matrices.\n",
    "3. Transpose: Flipping a matrix along its main diagonal.\n",
    "4. Indexing and Slicing: Accessing specific elements or sub-tensors within a tensor.\n",
    "5. Reshaping: Changing the shape of a tensor while maintaining the same number of elements.\n",
    "6. Reduction Operations: Calculating statistics like sum, mean, min, max along certain dimensions.\n",
    "7. Broadcasting: Implicitly expanding tensors of smaller shape to match the shape of larger tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd554bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n",
      "tensor([1., 1.])\n",
      "torch.Size([2, 2])\n",
      "tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "#2d tensor\n",
    "x = torch.ones(100,2)\n",
    "print(x.shape)\n",
    "print(x[1])\n",
    "\n",
    "y = torch.ones(2,2)\n",
    "print(y.shape)\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1385eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.0000e+00, -2.9000e+00, -2.8000e+00, -2.7000e+00, -2.6000e+00,\n",
      "        -2.5000e+00, -2.4000e+00, -2.3000e+00, -2.2000e+00, -2.1000e+00,\n",
      "        -2.0000e+00, -1.9000e+00, -1.8000e+00, -1.7000e+00, -1.6000e+00,\n",
      "        -1.5000e+00, -1.4000e+00, -1.3000e+00, -1.2000e+00, -1.1000e+00,\n",
      "        -1.0000e+00, -9.0000e-01, -8.0000e-01, -7.0000e-01, -6.0000e-01,\n",
      "        -5.0000e-01, -4.0000e-01, -3.0000e-01, -2.0000e-01, -1.0000e-01,\n",
      "        -2.3842e-08,  1.0000e-01,  2.0000e-01,  3.0000e-01,  4.0000e-01,\n",
      "         5.0000e-01,  6.0000e-01,  7.0000e-01,  8.0000e-01,  9.0000e-01,\n",
      "         1.0000e+00,  1.1000e+00,  1.2000e+00,  1.3000e+00,  1.4000e+00,\n",
      "         1.5000e+00,  1.6000e+00,  1.7000e+00,  1.8000e+00,  1.9000e+00,\n",
      "         2.0000e+00,  2.1000e+00,  2.2000e+00,  2.3000e+00,  2.4000e+00,\n",
      "         2.5000e+00,  2.6000e+00,  2.7000e+00,  2.8000e+00,  2.9000e+00])\n",
      "tensor([[-3.0000e+00],\n",
      "        [-2.9000e+00],\n",
      "        [-2.8000e+00],\n",
      "        [-2.7000e+00],\n",
      "        [-2.6000e+00],\n",
      "        [-2.5000e+00],\n",
      "        [-2.4000e+00],\n",
      "        [-2.3000e+00],\n",
      "        [-2.2000e+00],\n",
      "        [-2.1000e+00],\n",
      "        [-2.0000e+00],\n",
      "        [-1.9000e+00],\n",
      "        [-1.8000e+00],\n",
      "        [-1.7000e+00],\n",
      "        [-1.6000e+00],\n",
      "        [-1.5000e+00],\n",
      "        [-1.4000e+00],\n",
      "        [-1.3000e+00],\n",
      "        [-1.2000e+00],\n",
      "        [-1.1000e+00],\n",
      "        [-1.0000e+00],\n",
      "        [-9.0000e-01],\n",
      "        [-8.0000e-01],\n",
      "        [-7.0000e-01],\n",
      "        [-6.0000e-01],\n",
      "        [-5.0000e-01],\n",
      "        [-4.0000e-01],\n",
      "        [-3.0000e-01],\n",
      "        [-2.0000e-01],\n",
      "        [-1.0000e-01],\n",
      "        [-2.3842e-08],\n",
      "        [ 1.0000e-01],\n",
      "        [ 2.0000e-01],\n",
      "        [ 3.0000e-01],\n",
      "        [ 4.0000e-01],\n",
      "        [ 5.0000e-01],\n",
      "        [ 6.0000e-01],\n",
      "        [ 7.0000e-01],\n",
      "        [ 8.0000e-01],\n",
      "        [ 9.0000e-01],\n",
      "        [ 1.0000e+00],\n",
      "        [ 1.1000e+00],\n",
      "        [ 1.2000e+00],\n",
      "        [ 1.3000e+00],\n",
      "        [ 1.4000e+00],\n",
      "        [ 1.5000e+00],\n",
      "        [ 1.6000e+00],\n",
      "        [ 1.7000e+00],\n",
      "        [ 1.8000e+00],\n",
      "        [ 1.9000e+00],\n",
      "        [ 2.0000e+00],\n",
      "        [ 2.1000e+00],\n",
      "        [ 2.2000e+00],\n",
      "        [ 2.3000e+00],\n",
      "        [ 2.4000e+00],\n",
      "        [ 2.5000e+00],\n",
      "        [ 2.6000e+00],\n",
      "        [ 2.7000e+00],\n",
      "        [ 2.8000e+00],\n",
      "        [ 2.9000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(-3,3,0.1)\n",
    "print(x)\n",
    "x = x.view(-1,1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf42762",
   "metadata": {},
   "source": [
    "### Derivatives of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81445402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfa431",
   "metadata": {},
   "source": [
    "this requires_grad parameter will tell pytorch that we would be using evaluating functions and derivatives of x using this value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b21ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d382bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313f06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cbbab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed94417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x**2 + 2*x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c7424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa713a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960980a",
   "metadata": {},
   "source": [
    "### Partial Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f7d148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor(1.0, requires_grad= True)\n",
    "v = torch.tensor(2.0, requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05c54bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= u*v + u**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0897343",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c715c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c78ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba98097",
   "metadata": {},
   "source": [
    "### Differentiation wrt x at multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7522c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-20.0000, -17.8947, -15.7895, -13.6842, -11.5789,  -9.4737,  -7.3684,\n",
       "         -5.2632,  -3.1579,  -1.0526,   1.0526,   3.1579,   5.2632,   7.3684,\n",
       "          9.4737,  11.5789,  13.6842,  15.7895,  17.8947,  20.0000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.linspace(-10, 10, 20, requires_grad= True)\n",
    "y= torch.sum(x**2)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76267b",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78dc44",
   "metadata": {},
   "source": [
    "## Dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a325d48",
   "metadata": {},
   "source": [
    "In PyTorch, a Dataset is an abstraction that represents a collection of data, such as training or testing examples, that you'll use to train and evaluate machine learning models. The Dataset class provides an interface to access individual data points, allowing you to easily load and preprocess data for training and inference. It's a fundamental component in the PyTorch data loading pipeline.\n",
    "\n",
    "To use a custom dataset in PyTorch, you typically create a subclass of the torch.utils.data.Dataset class and implement two key methods: __len__() and __getitem__().\n",
    "\n",
    "Here's an example of how you might create a custom dataset in PyTorch:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "# Create some example data\n",
    "data = torch.arange(10)  # A tensor of [0, 1, ..., 9]\n",
    "\n",
    "# Create an instance of the CustomDataset\n",
    "custom_dataset = CustomDataset(data)\n",
    "\n",
    "# Create a DataLoader to iterate through the dataset\n",
    "dataloader = DataLoader(custom_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "# Iterate through batches of the dataset\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bba48e",
   "metadata": {},
   "source": [
    "### Dataset Class:\n",
    "\n",
    "**1. Data Representation:**\n",
    "The primary role of the Dataset class is to provide an interface for representing your data. It encapsulates your data points and makes them accessible in a structured manner. This includes loading and storing individual data points.\n",
    "\n",
    "**2. Custom Data Loading:**\n",
    "The Dataset class allows you to implement custom data loading and preprocessing logic. You can define how to read data from files, apply transformations, and prepare data points for training or evaluation.\n",
    "\n",
    "**3. Data Access by Index:**\n",
    "It enables you to access individual data points using their indices. The \\_\\_getitem\\_\\_() method in your custom dataset class defines how a specific data point is accessed.\n",
    "\n",
    "**4. Size Information:**\n",
    "The \\_\\_len\\_\\_() method in your Dataset class returns the total number of data points in the dataset, providing size information.\n",
    "\n",
    "### DataLoader Class:\n",
    "**1. Batching:**\n",
    "The DataLoader class takes care of dividing your dataset into smaller batches. Batching is essential for efficient training, as models often learn better and faster when trained on batches of data rather than individual data points.\n",
    "\n",
    "**2. Shuffling:**\n",
    "It can shuffle the data within each epoch to prevent the model from learning any order-based patterns. Shuffling helps to ensure randomness and prevents biases during training.\n",
    "\n",
    "**3. Parallel Loading:**\n",
    "The DataLoader class can load and preprocess batches of data in parallel, leveraging multiple CPU cores. This accelerates the data loading process, especially for large datasets.\n",
    "\n",
    "**4. Iterating Through Batches:**\n",
    "It provides an iterator interface that allows you to easily loop through batches of data. You can use a for loop to iterate through batches in your training or evaluation loop.\n",
    "\n",
    "**5. Convenient Usage:**\n",
    "The DataLoader abstracts away the complexity of batching, shuffling, and parallel loading. It provides a convenient way to access data in a format suitable for training and evaluation.\n",
    "\n",
    "In summary, the Dataset class focuses on representing your data and providing customized data loading logic, while the DataLoader class handles the mechanics of batching, shuffling, parallel loading, and iteration. Together, they provide an efficient and convenient way to work with large datasets during machine learning model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91032e56",
   "metadata": {},
   "source": [
    "### Example of creating dataset and applying single transform with is not mentioned in dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6dd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2., 2.]), tensor([1.]))\n",
      "tensor([3., 3.]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset\n",
    "class toy_set(Dataset):\n",
    "    def __init__(self,length=100,transform=None):\n",
    "        self.x= 2 * torch.ones(length,2)\n",
    "        self.y= torch.ones(length,1)\n",
    "        self.len= length\n",
    "        self.transform= transform\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sample= self.x[index],self.y[index]\n",
    "        if self.transform:\n",
    "            sample= self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "#transform\n",
    "class add_mult(object):\n",
    "    def __init__(self,addx=1,muly=1):\n",
    "        self.addx=addx\n",
    "        self.muly=muly\n",
    "    def __call__(self,sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x+self.addx\n",
    "        y=y*self.muly\n",
    "        sample=x,y\n",
    "        return sample\n",
    "\n",
    "#create dataset object\n",
    "dataset= toy_set()\n",
    "#create transform object\n",
    "a_m= add_mult()\n",
    "#apply transform to a datapoint\n",
    "print(dataset[0])\n",
    "x_,y_=a_m(dataset[0])\n",
    "print(x_,y_)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd4c17",
   "metadata": {},
   "source": [
    "### Example of creating dataset and applying single transform automatically when we access a datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3ad1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([3., 3.]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset\n",
    "class toy_set(Dataset):\n",
    "    def __init__(self,length=100,transform=None):\n",
    "        self.x= 2 * torch.ones(length,2)\n",
    "        self.y= torch.ones(length,1)\n",
    "        self.len= length\n",
    "        self.transform= transform\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sample= self.x[index],self.y[index]\n",
    "        if self.transform:\n",
    "            sample= self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "#transform\n",
    "class add_mult(object):\n",
    "    def __init__(self,addx=1,muly=1):\n",
    "        self.addx=addx\n",
    "        self.muly=muly\n",
    "    def __call__(self,sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x+self.addx\n",
    "        y=y*self.muly\n",
    "        sample=x,y\n",
    "        return sample\n",
    "\n",
    "#transform object\n",
    "a_m= add_mult()\n",
    "\n",
    "#dataset object\n",
    "# '_' indicates transform have been applied \n",
    "dataset_= toy_set(transform=a_m)\n",
    "print(dataset_[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3fb0c",
   "metadata": {},
   "source": [
    "### Transform Compose: to apply several transform from outside when we access a datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4605b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2., 2.]), tensor([1.]))\n",
      "tensor([300., 300.]) tensor([100.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset\n",
    "class toy_set(Dataset):\n",
    "    def __init__(self,length=100,transform=None):\n",
    "        self.x= 2 * torch.ones(length,2)\n",
    "        self.y= torch.ones(length,1)\n",
    "        self.len= length\n",
    "        self.transform= transform\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sample= self.x[index],self.y[index]\n",
    "        if self.transform:\n",
    "            sample= self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class add_mult(object):\n",
    "    def __init__(self,addx=1,muly=1):\n",
    "        self.addx=addx\n",
    "        self.muly=muly\n",
    "    def __call__(self,sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x+self.addx\n",
    "        y=y*self.muly\n",
    "        sample=x,y\n",
    "        return sample\n",
    "\n",
    "class mult(object):\n",
    "    def __init__(self,mul=100):\n",
    "        self.mul=mul\n",
    "    def __call__(self,sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x*self.mul\n",
    "        y=y*self.mul\n",
    "        sample=x,y\n",
    "        return sample\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "#create a chain of transform\n",
    "data_transform = transforms.Compose([add_mult(),mult()])\n",
    "\n",
    "#create dataset object\n",
    "dataset= toy_set()\n",
    "print(dataset[0])\n",
    "x_,y_= data_transform(dataset[0])\n",
    "print(x_,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a588416",
   "metadata": {},
   "source": [
    "### Transform Compose: to apply several transform automatically when we access a datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1856bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([300., 300.]), tensor([100.]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset\n",
    "class toy_set(Dataset):\n",
    "    def __init__(self,length=100,transform=None):\n",
    "        self.x= 2 * torch.ones(length,2)\n",
    "        self.y= torch.ones(length,1)\n",
    "        self.len= length\n",
    "        self.transform= transform\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sample= self.x[index],self.y[index]\n",
    "        if self.transform:\n",
    "            sample= self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class add_mult(object):\n",
    "    def __init__(self,addx=1,muly=1):\n",
    "        self.addx=addx\n",
    "        self.muly=muly\n",
    "    def __call__(self,sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x+self.addx\n",
    "        y=y*self.muly\n",
    "        sample=x,y\n",
    "        return sample\n",
    "\n",
    "class mult(object):\n",
    "    def __init__(self,mul=100):\n",
    "        self.mul=mul\n",
    "    def __call__(self,sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x*self.mul\n",
    "        y=y*self.mul\n",
    "        sample=x,y\n",
    "        return sample\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "#create a chain of transform\n",
    "data_transform = transforms.Compose([add_mult(),mult()])\n",
    "\n",
    "#create dataset object and pass transforms object\n",
    "dataset_= toy_set(transform= data_transform)\n",
    "print(dataset_[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c1cf0",
   "metadata": {},
   "source": [
    "# torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242b1ca",
   "metadata": {},
   "source": [
    "torchvision is a sub-library of PyTorch that provides various utilities and tools for working with computer vision tasks. One of the key functionalities of torchvision is to provide pre-built datasets and data transformation mechanisms that are commonly used in computer vision tasks. The torchvision.datasets module offers access to several popular datasets, and the torchvision.transforms module provides transformations for data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292faa6",
   "metadata": {},
   "source": [
    "### torchvision dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2821abe",
   "metadata": {},
   "source": [
    "One of the significant use cases for torchvision.datasets is to provide standardized datasets that enable researchers and practitioners to compare different machine learning models in a consistent manner. These datasets act as a common ground for evaluating the performance of various algorithms and models on the same data, making comparisons more meaningful and fair.\n",
    "\n",
    "When comparing models, using the same dataset allows researchers and practitioners to focus on the differences in algorithms and architectures rather than variations in the datasets themselves. This standardized approach enhances the credibility of the comparison and helps the community identify which methods perform better under specific conditions.\n",
    "\n",
    "For example, when comparing image classification models, you might use datasets like MNIST, CIFAR-10, or ImageNet to evaluate how different models perform on different scales of complexity and diversity in the dataset. By using well-established datasets, you can ensure that the differences observed in model performance are likely due to the model itself and not the idiosyncrasies of the data.\n",
    "\n",
    "Using torchvision.datasets for model comparison also streamlines the process, as you can readily access and preprocess these datasets without needing to manually curate, format, and preprocess the data yourself. This is especially valuable when you want to focus on the model's architecture, training process, and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3fb20",
   "metadata": {},
   "source": [
    "### torchvision dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a42184",
   "metadata": {},
   "source": [
    "When it comes to data loaders in torchvision, they are used to efficiently load and preprocess data from datasets for training, validation, and testing purposes. Data loaders make it easier to handle large datasets and manage memory effectively, while also allowing for various data augmentation and preprocessing techniques.\n",
    "\n",
    "Here are the main features and uses of torchvision data loaders:\n",
    "\n",
    "**1. Batching:** Data loaders automatically batch the data, which means that instead of loading the entire dataset at once, they load a small batch of samples (images and labels) into memory. This is essential for training neural networks efficiently, as it enables batch processing, which can significantly speed up training.\n",
    "\n",
    "**2. Shuffling:** Data loaders can shuffle the dataset before each epoch during training. Shuffling the data helps prevent the model from memorizing the order of samples and enhances its generalization ability.\n",
    "\n",
    "**3. Parallel Loading:** Data loaders can load batches in parallel using multiple workers. This helps to utilize the CPU cores efficiently and reduces the time spent waiting for data loading, which can speed up training.\n",
    "\n",
    "**4. Data Augmentation:** torchvision provides various data augmentation techniques through the transforms module. You can apply transformations like random cropping, resizing, flipping, and color jittering to augment your dataset, which can improve the model's ability to generalize.\n",
    "\n",
    "**5. Normalization:** You can apply normalization to the dataset using the transforms.Normalize transformation. Normalization ensures that pixel values have a consistent scale, which can help stabilize the training process.\n",
    "\n",
    "**6. Custom Dataset Support:** In addition to pre-built datasets, you can also use data loaders with your custom datasets by creating a custom dataset class that adheres to the torch.utils.data.Dataset interface.\n",
    "\n",
    "In summary, torchvision data loaders are a crucial tool for efficiently loading, preprocessing, and augmenting datasets for training and evaluation in computer vision tasks. They provide an effective way to manage memory usage, parallelize data loading, and apply various preprocessing techniques to enhance the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26cf5b2",
   "metadata": {},
   "source": [
    "### Download MNSIT pre- built dataset and Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa59a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#Download MNSIT dataset\n",
    "mnist_train_dataset = MNIST(root='./resources/data', train=True, download=True, transform=transform)\n",
    "mnist_test_dataset = MNIST(root='./resources/data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Create data loaders\n",
    "batch_size=64\n",
    "train_loader= DataLoader(mnist_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader= DataLoader(mnist_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456573f2",
   "metadata": {},
   "source": [
    "## Custom module in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f49f81",
   "metadata": {},
   "source": [
    "In PyTorch, a custom module is typically a class that inherits from the torch.nn.Module base class. This allows you to define your own neural network architectures, encapsulate parameters, and create complex operations. Here's a basic example of creating a custom module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80f2895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0197,  0.0136,  0.3860,  0.3506, -0.4686],\n",
      "        [-0.1528, -0.4839,  0.4383,  0.2422, -0.3714],\n",
      "        [-0.3400, -0.6243,  0.6892,  0.2933, -0.4380],\n",
      "        [-0.0349,  0.0462,  0.2903,  0.2954, -0.2494],\n",
      "        [ 0.2567, -0.1921,  0.0096, -0.0072, -0.1223],\n",
      "        [ 0.0458, -0.3592,  0.2569,  0.4142, -0.2592],\n",
      "        [ 0.3067,  0.1053,  0.1666,  0.0559, -0.0421],\n",
      "        [ 0.0919, -0.0995,  0.1116,  0.2467, -0.1492],\n",
      "        [-0.0205, -0.3303,  0.2824,  0.3910, -0.2438],\n",
      "        [-0.1113, -0.8372,  0.2890,  0.3676, -0.4409],\n",
      "        [-0.0110, -0.0063,  0.3826,  0.0114, -0.1678],\n",
      "        [-0.0869, -0.2933,  0.4273, -0.1934, -0.0405],\n",
      "        [ 0.1212, -0.2647,  0.4032,  0.5093, -0.1859],\n",
      "        [ 0.1697, -0.2908,  0.2509,  0.0557, -0.0071],\n",
      "        [ 0.0758, -0.0367,  0.3924,  0.0114, -0.1779],\n",
      "        [-0.0682, -0.3100,  0.3005,  0.2177, -0.3292],\n",
      "        [ 0.1382, -0.4229,  0.3518,  0.4382, -0.2012],\n",
      "        [ 0.2454, -0.2646,  0.3053,  0.2587, -0.0134],\n",
      "        [ 0.1066, -0.0647,  0.3821,  0.2687, -0.1233],\n",
      "        [ 0.0748, -0.0673, -0.0445, -0.0241, -0.1175],\n",
      "        [ 0.3814, -0.4047,  0.0798,  0.1552, -0.1739],\n",
      "        [ 0.1628,  0.0826,  0.1510,  0.0723, -0.1145],\n",
      "        [ 0.0886, -0.3325,  0.4049, -0.1374,  0.1607],\n",
      "        [ 0.1887, -0.3299,  0.0408,  0.0624, -0.1751],\n",
      "        [ 0.3651,  0.1577, -0.0763,  0.0009, -0.1913],\n",
      "        [ 0.1657, -0.0534,  0.1344,  0.4106, -0.2349],\n",
      "        [-0.0030, -0.4942,  0.2469, -0.0667,  0.0802],\n",
      "        [ 0.1616,  0.2079,  0.1738,  0.1413, -0.2160],\n",
      "        [ 0.2519, -0.0655,  0.2768,  0.4186, -0.1365],\n",
      "        [-0.0287, -0.0337,  0.0994,  0.1881, -0.1835],\n",
      "        [ 0.0293, -0.1557,  0.2321,  0.3584, -0.3221],\n",
      "        [ 0.2404, -0.0609,  0.3194,  0.1070,  0.0199]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomModule, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "#The __init__ method sets up the layers, and the forward method defines the forward pass of the network.\n",
    "\n",
    "#Remember to always call the parent class's __init__ method using super() to properly initialize the module.\n",
    "\n",
    "# Instantiate the custom module\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "model = CustomModule(input_size, hidden_size, output_size)\n",
    "\n",
    "# Create some dummy input data\n",
    "dummy_input = torch.randn(32, input_size)\n",
    "\n",
    "# Pass the input through the model\n",
    "output = model(dummy_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49598ffa",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083e0c4",
   "metadata": {},
   "source": [
    "It is used to find the minimum of a function, it can be applied to a function with multiple dimensions.\n",
    "\n",
    "1)what should be learning rate: \n",
    "  if we choose the learning rate as high, sometime we miss the minima. if we select the learning rate too low, then the  number\n",
    "  of iteration will increase.\n",
    "\n",
    "2)when to stop the gradient discent: \n",
    "   see if loss starts increasing. record a few iterations of gradient descent  and record the results in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509b1ee",
   "metadata": {},
   "source": [
    "## Cost/Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406610a7",
   "metadata": {},
   "source": [
    "In order to find the best values for the parameters of a model, we need to find how good our model is, a quantity that is near zero when our model provides a good estimate and large when our model is bad, we call this quantity the loss/cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dc5af",
   "metadata": {},
   "source": [
    "## Stocastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc7320",
   "metadata": {},
   "source": [
    "In SGD, instead of using the entire dataset for each iteration, only a single random training example (or a small batch) is selected to calculate the gradient and update the model parameters. This random selection introduces randomness into the optimization process, hence the term “stochastic” in stochastic Gradient Descent.\n",
    "\n",
    "The problem with stocastic gradient descent is that the value of cost/loss fluctuate rapildy with each iteration.\n",
    "\n",
    "In SGD, no. of epochs is not same as number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ae55f",
   "metadata": {},
   "source": [
    "### Example: performing stocastic gradient descent using dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6476.763609051704, 1225.0185958952643, 291.4723268855596, 69.35072039815714]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(1)\n",
    "\n",
    "w= torch.tensor(-15.0, requires_grad=True)\n",
    "b= torch.tensor(-10.0, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    y=w*x+b\n",
    "    return y\n",
    "\n",
    "def criterion(yaht,y):\n",
    "    return torch.mean((yhat-y)**2)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x= torch.arange(-3,3,0.1).view(-1,1)\n",
    "        self.y= 3*self.x+1\n",
    "        self.len= self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "dataset= Data()\n",
    "\n",
    "trainloader= DataLoader(dataset=dataset, batch_size=1)\n",
    "\n",
    "lr= 0.1\n",
    "LOSS=[]\n",
    "\n",
    "for epoch in range(4):\n",
    "    total=0\n",
    "    for x,y in trainloader:\n",
    "        yhat= forward(x)\n",
    "        loss= criterion(yhat,y)\n",
    "        loss.backward()\n",
    "        \n",
    "        #update the parameters\n",
    "        w.data -= lr * w.grad.data\n",
    "        b.data -= lr * b.grad.data\n",
    "        \n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "        total+= loss.item()\n",
    "    LOSS.append(total)\n",
    "\n",
    "print(LOSS)\n",
    "#show error reduced after each epoch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a plot\n",
    "plt.plot(LOSS, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epoch')\n",
    "plt.title('loss v/s epoch graph')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3d3fa",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2faef03",
   "metadata": {},
   "source": [
    "It has many advantages, one important one is that it will allow you to process larger datasets, that you will not be able to fit into memory, because it splits up the dataset into smaller samples.\n",
    "\n",
    "In Mini-BGD, the relationship between batch size, number of iterations and epochs is a little more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32b484",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2292f1",
   "metadata": {},
   "source": [
    "## torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef054d",
   "metadata": {},
   "source": [
    "### Example: Linear Regression 1D: Training two parameters with mini-batch gradient descent using dataset, dataloader,   torch.optim.SGD and torch.nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf7140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
